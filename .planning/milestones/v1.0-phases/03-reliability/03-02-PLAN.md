---
phase: 03-reliability
plan: 02
type: execute
wave: 2
depends_on:
  - 03-01
files_modified:
  - src/openclawpack/output/formatter.py
  - src/openclawpack/output/schema.py
  - src/openclawpack/output/__init__.py
  - src/openclawpack/transport/client.py
  - src/openclawpack/cli.py
  - tests/test_output/test_formatter.py
  - tests/test_output/test_schema.py
  - tests/test_cli.py
autonomous: true
requirements:
  - OUT-03
  - OUT-04

must_haves:
  truths:
    - "Running any command with --output-format text produces human-readable lines instead of JSON"
    - "Running any command with --output-format json (or no flag) produces JSON as before"
    - "Every command response from Claude SDK includes token count and total_cost_usd in the usage dict"
    - "Local-only commands (status) return usage with zeroed token counts and cost instead of None"
  artifacts:
    - path: "src/openclawpack/output/formatter.py"
      provides: "format_text() function converting CommandResult to human-readable string"
      min_lines: 30
    - path: "src/openclawpack/output/schema.py"
      provides: "CommandResult.to_text() convenience method"
      contains: "to_text"
    - path: "src/openclawpack/cli.py"
      provides: "--output-format flag on app callback dispatching between json and text"
      contains: "--output-format"
    - path: "tests/test_output/test_formatter.py"
      provides: "Tests for format_text() with success/error/usage/session cases"
      min_lines: 40
  key_links:
    - from: "src/openclawpack/cli.py"
      to: "src/openclawpack/output/formatter.py"
      via: "lazy import of format_text in _output() helper"
      pattern: "from openclawpack\\.output\\.formatter import format_text"
    - from: "src/openclawpack/output/schema.py"
      to: "src/openclawpack/output/formatter.py"
      via: "to_text() delegates to format_text()"
      pattern: "format_text"
    - from: "src/openclawpack/transport/client.py"
      to: "ResultMessage.total_cost_usd"
      via: "usage dict enrichment with total_cost_usd"
      pattern: "total_cost_usd"
---

<objective>
Add --output-format text|json CLI flag for human-readable output and enrich usage metadata with token counts and cost.

Purpose: OUT-03 enables human operators to read command output without parsing JSON. OUT-04 enables agent budget management by providing token count and cost in every response.

Output: formatter.py module with format_text(), updated CommandResult with to_text(), updated CLI with --output-format flag, enriched usage dict in transport, and tests.
</objective>

<execution_context>
@/Users/mit/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mit/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-reliability/3-RESEARCH.md
@.planning/phases/03-reliability/03-01-SUMMARY.md

@src/openclawpack/output/schema.py
@src/openclawpack/output/__init__.py
@src/openclawpack/transport/client.py
@src/openclawpack/cli.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create text formatter and enrich usage metadata</name>
  <files>
    src/openclawpack/output/formatter.py
    src/openclawpack/output/schema.py
    src/openclawpack/output/__init__.py
    src/openclawpack/transport/client.py
    tests/test_output/test_formatter.py
    tests/test_output/test_schema.py
  </files>
  <action>
**Create `src/openclawpack/output/formatter.py`:**

Implement `format_text(result: CommandResult) -> str` function:
- Line 1: `Status: SUCCESS` or `Status: FAILED`
- If `result.result` is not None: blank line then the result text (truncate to 2000 chars with "... (truncated)" suffix if longer)
- If `result.errors` is not empty: blank line, `Errors:` header, then `  - {err}` for each error
- If `result.session_id` is not None: blank line, `Session: {session_id}`
- If `result.usage` is not None: `Tokens: {input_tokens:,} input / {output_tokens:,} output` (comma-formatted), and if `total_cost_usd` key exists: `Cost: ${cost:.4f}`
- Final line: `Duration: {duration_ms:,}ms` (comma-formatted)
- Use `from __future__ import annotations` and TYPE_CHECKING guard for CommandResult import to avoid circular imports

**Update `src/openclawpack/output/schema.py`:**

Add `to_text(self) -> str` method to CommandResult:
```python
def to_text(self) -> str:
    """Serialize to human-readable text string."""
    from openclawpack.output.formatter import format_text
    return format_text(self)
```
Place it right after the existing `to_json()` method.

**Update `src/openclawpack/output/__init__.py`:**

Add `format_text` to imports and `__all__`:
```python
from openclawpack.output.formatter import format_text
__all__ = ["CommandResult", "format_text"]
```

**Update `src/openclawpack/transport/client.py` (usage enrichment in `_run_once`):**

In `_run_once()` (created by Plan 03-01), modify the CommandResult construction at the end:
- Replace the direct `usage=result_message.usage` with enriched version:
  ```python
  # Enrich usage with token counts and cost (OUT-04)
  usage = dict(result_message.usage) if result_message.usage else {}
  if hasattr(result_message, 'total_cost_usd') and result_message.total_cost_usd is not None:
      usage["total_cost_usd"] = result_message.total_cost_usd
  usage.setdefault("input_tokens", 0)
  usage.setdefault("output_tokens", 0)
  ```
- Use the enriched `usage` dict in the CommandResult constructor

**Create `tests/test_output/test_formatter.py`:**

- `test_format_text_success_result`: CommandResult.ok("done") -> contains "Status: SUCCESS" and "done"
- `test_format_text_error_result`: CommandResult.error("fail") -> contains "Status: FAILED" and "Errors:" and "fail"
- `test_format_text_with_usage`: CommandResult with usage={"input_tokens": 1500, "output_tokens": 300, "total_cost_usd": 0.0123} -> contains "Tokens: 1,500 input / 300 output" and "Cost: $0.0123"
- `test_format_text_with_session_id`: CommandResult with session_id="abc-123" -> contains "Session: abc-123"
- `test_format_text_long_result_truncated`: CommandResult with result="x" * 3000 -> contains "... (truncated)" and length of result portion is capped
- `test_format_text_no_usage`: CommandResult with usage=None -> does NOT contain "Tokens:" line
- `test_format_text_usage_without_cost`: usage={"input_tokens": 100, "output_tokens": 50} -> contains "Tokens:" but NOT "Cost:"
- `test_format_text_duration`: CommandResult with duration_ms=12345 -> contains "Duration: 12,345ms"

**Update `tests/test_output/test_schema.py`:**

- Add `test_to_text_method`: verify CommandResult.ok("hello").to_text() returns a string containing "Status: SUCCESS"
  </action>
  <verify>
Run `python -m pytest tests/test_output/ -v` -- all tests pass.
Run `python -c "from openclawpack.output import format_text, CommandResult; r = CommandResult.ok('hello', usage={'input_tokens': 100, 'output_tokens': 50, 'total_cost_usd': 0.01}); print(r.to_text())"` -- prints human-readable output with tokens and cost.
  </verify>
  <done>
format_text() renders CommandResult as human-readable lines. CommandResult.to_text() delegates to format_text(). Usage dict always includes input_tokens, output_tokens, and total_cost_usd when returned from SDK. All formatter and schema tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add --output-format CLI flag and update output dispatch</name>
  <files>
    src/openclawpack/cli.py
    tests/test_cli.py
  </files>
  <action>
**Update `src/openclawpack/cli.py`:**

1. Add `output_format` to the `@app.callback()` main function:
   ```python
   output_format: str = typer.Option(
       "json",
       "--output-format",
       help="Output format: json (default) or text.",
   ),
   ```
   Store in ctx.obj: `ctx.obj["output_format"] = output_format`

2. Update `_output()` helper to accept and use output_format:
   ```python
   def _output(result: object, quiet: bool, output_format: str = "json") -> None:
       if quiet:
           return
       if output_format == "text":
           from openclawpack.output.formatter import format_text
           typer.echo(format_text(result))
       else:
           typer.echo(result.to_json())
   ```

3. Update `_resolve_options()` to include output_format:
   - Add `output_format_opt: str` parameter (default "json")
   - Return it as 4th element of tuple: `tuple[Optional[str], bool, bool, str]`
   - Resolution: `output_format = output_format_opt if output_format_opt != "json" else ctx.obj.get("output_format", "json")`
   - Actually, simpler approach: just read from ctx.obj in each command since --output-format is a global option. Keep _resolve_options unchanged. Each command reads `ctx.obj.get("output_format", "json")` and passes to `_output()`.

4. Update each command's `_output()` call to pass the output_format:
   - In `new_project`: `_output(result, quiet, ctx.obj.get("output_format", "json"))`
   - In `plan_phase`: `_output(result, quiet, ctx.obj.get("output_format", "json"))`
   - In `execute_phase`: `_output(result, quiet, ctx.obj.get("output_format", "json"))`
   - In `status`: `_output(result, quiet, ctx.obj.get("output_format", "json"))`

5. Update status command to return zero usage instead of None (Pitfall 4 from research):
   - In the `status` command function, after getting `result` from `status_workflow()`: if `result.usage is None`, set `result.usage = {"input_tokens": 0, "output_tokens": 0, "total_cost_usd": 0.0}`
   - This ensures `--output-format text` always has usage data to render

**Update `tests/test_cli.py`:**

Add tests:
- `test_output_format_flag_in_help`: invoke `--help` and verify `--output-format` appears
- `test_output_format_text_status`: invoke `status --output-format text --project-dir <tmp>` where tmp has valid .planning/ -- verify output contains "Status:" (text format) not `{"success":` (json format)
- `test_output_format_json_default`: invoke `status --project-dir <tmp>` -- verify output contains `"success"` (json format)
- `test_output_format_text_with_usage`: mock a workflow to return CommandResult with usage dict, invoke with --output-format text, verify "Tokens:" and "Cost:" appear
  </action>
  <verify>
Run `python -m pytest tests/test_cli.py -v` -- all tests pass (new + existing).
Run `python -m pytest tests/ -v` -- full suite passes.
Run `python -c "from openclawpack.cli import app; from typer.testing import CliRunner; r = CliRunner().invoke(app, ['--help']); assert '--output-format' in r.output; print('OK')"` -- flag visible in help.
  </verify>
  <done>
--output-format text|json flag works on all commands. Text format shows human-readable lines with status, result, errors, session, tokens, cost, and duration. JSON format (default) is unchanged. Status command returns zero usage instead of None. All CLI tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/ -v` -- all tests pass (no regressions from Plan 03-01 or new tests)
2. `python -c "from openclawpack.output.formatter import format_text; print('OK')"` -- formatter module imports
3. `python -c "from openclawpack.output import CommandResult; r = CommandResult.ok('test', usage={'input_tokens': 500, 'output_tokens': 100, 'total_cost_usd': 0.005}); print(r.to_text())"` -- shows human-readable output with cost
4. `python -c "from openclawpack.cli import app; from typer.testing import CliRunner; r = CliRunner().invoke(app, ['--help']); assert '--output-format' in r.output; print('OK')"` -- flag in global help
</verification>

<success_criteria>
- format_text() produces human-readable output from CommandResult
- CommandResult.to_text() convenience method works
- --output-format text produces text output, --output-format json (default) produces JSON
- Usage dict from SDK always contains input_tokens, output_tokens, and total_cost_usd
- Local-only commands return zero usage instead of None
- All existing and new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/03-reliability/03-02-SUMMARY.md`
</output>
